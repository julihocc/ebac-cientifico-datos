{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "#### by **Ivan Alducin**\n",
    "<p><img src=\"https://preview.redd.it/rfgtsej8fhv71.jpg?auto=webp&s=99a5d000ff2baaac79a8d15c7135c3677f105159\" width=\"1000\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "<p>Vamos a trabajar con el conjunto de datos de <code>Heart Attack</code>, el objetivo es predecir bajo que escenario es más probable que un paciente pueda tener un ataque al corazón  Un experto en medicina cardiovasuclar puede predecir esto sin hacer uso de <i>Machine Learning</i>, pero probablemente no instantáneamente, ¡y ciertamente no si estamos tratando con cientos o miles de muestras!.\n",
    "    \n",
    "A continuación una breve explicación de las variables del dataset:\n",
    "    \n",
    "- <b>age:</b> Age of the patient\n",
    "- <b>sex:</b> Sex of the patient\n",
    "- <b>cp:</b> Chest pain type ~ 0 = Typical Angina, 1 = Atypical Angina, 2 = Non-anginal Pain, 3 = Asymptomatic\n",
    "- <b>trtbps:</b> Resting blood pressure (in mm Hg)\n",
    "- <b>chol:</b> Cholestoral in mg/dl fetched via BMI sensor\n",
    "- <b>fbs:</b> (fasting blood sugar > 120 mg/dl) ~ 1 = True, 0 = False\n",
    "- <b>restecg:</b> Resting electrocardiographic results ~ 0 = Normal, 1 = ST-T wave normality, 2 = Left ventricular hypertrophy\n",
    "- <b>thalachh:</b> Maximum heart rate achieved\n",
    "- <b>oldpeak:</b> Previous peak\n",
    "- <b>slp:</b> Slope\n",
    "- <b>caa:</b> Number of major vessels\n",
    "- <b>thall:</b> Thalium Stress Test result ~ (0,3)\n",
    "- <b>exng:</b> Exercise induced angina ~ 1 = Yes, 0 = No\n",
    "- <b>output:</b>  Target variable</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo Heart Attack.csv - ¿Cuales son los factores que pueden incrementar o disminuir la probabilidad de un ataque al corazón?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(____)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer EDA (Exploratory Data Analysis) suele ser un tanto laborioso dependiendo del detalle al que se quiera llevar, pero prueba la siguiente librería, puede que a partir de ahora, tu EDA sea más fácil ;)\n",
    "!pip install dataprep\n",
    "from dataprep.eda import create_report\n",
    "\n",
    "create_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors\n",
    "<p>Habiendo hecho un Análisis Exploratorio de los factores que pueden o no tener más posibilidad de un ataque al corazón, es hora de crear tu primer clasificador!!! usando el algoritmo de k-NN.\n",
    "    \n",
    "<b>Nota</b>: es importante garantizar que los datos esten en el formato requerido por la librería de <code>scikit-learn</code>. La información debe estar en una matriz en la que cada columna sea una variable y cada fila una observación diferente, en este caso, el registro de análisis clinico por paciente. Y la variable objetivo debe ser una sola columna con el mismo número de observaciones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la librería para un clasificador k-NN de sklearn\n",
    "_____\n",
    "\n",
    "# Crea dos arreglos \"X\", \"y\" que contengan los valores de las variables independientes y la variable objetivo\n",
    "_____\n",
    "_____\n",
    "\n",
    "# Crea un clasificador k-NN con 6 vecinos\n",
    "_____\n",
    "\n",
    "# Ajusta el clasificador a las variables\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción\n",
    "<p>Una vez que entrenamos al clasificador k-NN, ahora lo podemos usar para predecir un nuevo registro. Para este caso,  no hay datos sin clasificar disponibles ya que todos se usaron para entrenar al modelo. Para poder calcular una predicción, vamos a usar el método <code>.predict()</code> pero, para esto vamos a simular una observación completamente nueva</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un arreglo simulando una observación\n",
    "X_new = ____\n",
    "\n",
    "# Predice la clasificación para el arreglo que creaste\n",
    "y_new_pred = ____\n",
    "print(\"Prediction: {}\".format(y_new_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de digitos\n",
    "<p>Hasta ahora, solo hemos realizado una clasificación binaria, ya que la variable objetivo tenía dos resultados posibles. En los siguientes ejercicios, trabajarás con el conjunto de datos de reconocimiento de dígitos MNIST, que tiene 10 clases, ¡los dígitos del 0 al 9! Una versión reducida del conjunto de datos <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST</a> es uno de los conjuntos de datos incluidos en <code>scikit-learn</code>\n",
    "\n",
    "Cada muestra de este conjunto de datos es una imagen de 28x28 que representa un dígito escrito a mano. Cada píxel está representado por un número entero en el rango de 1 a 784, lo que indica niveles variables de negro.\n",
    "\n",
    "<p><img src=\"https://miro.medium.com/max/1400/1*hVdoiW35FXUE-fZ0HI30Tw.jpeg\" width=\"350\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el archivo de MNIST\n",
    "digits = ____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una variable 'cols' para hacer referencia a todas las columnas que contienen la palabra 'pixel'\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a imprimir un digito\n",
    "i = ____\n",
    "print(\"El número es:\", df.loc[____, ____])\n",
    "plt.imshow(df.loc[____, cols].values.reshape((28,28)).astype(float), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test\n",
    "<p>Una de las principales diferencias entre la Estadística Clasica y el <i>Machine Learning</i> es la división del conjunto de datos en conjuntos de entrenamiento y prueba, con el objetivo de medir y cuantificar la precisión y el nivel de error en los datos que de alguna manera el modelo <i>\"No ha visto\"</i>. A continuación crearemos nuestros conjuntos de entrenamiento y prueba con el método <code>train_test_split</code> y mediremos cual es el nivel de precisión de nuestro modelo. El objetivo es <b>predecir cual es el digito dada una imagen</b>!!!. Para lo cual entrenaremos un clasificador <i>k-NN</i> a los datos de entrenamiento y luego calcularemos su precisión usando el método <code>accuracy_score()</code> en los datos de prueba ¿Como crees que en un modelo de Clasificación se calcule su precisión?. Parece bastante dificil, pero no lo es ;)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la librería para entrenamiento y prueba de datos y la librería para calcular la precisión\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea los arreglos para las variables independientes y la variable objetivo\n",
    "X = ____\n",
    "y = ____\n",
    "\n",
    "# Divide los arreglos anteriores en conjuntos de training y test en una proporcion del 70/30\n",
    "X_train, X_test, y_train, y_test = ____(____, ____, test_size = ____, random_state=____)\n",
    "\n",
    "# Instancia un clasificador k-NN con 14 vecinos\n",
    "knn = ____\n",
    "\n",
    "# Ajusta (Entrenamiento) el clasificador en el conjunto de entrenamiento\n",
    "____\n",
    "\n",
    "# Calcular las predicciones sobre el conjunto de prueba\n",
    "y_pred = \n",
    "\n",
    "# Verificar la precisión del modelo \n",
    "print(accuracy_score(____, ____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de tu imagen\n",
    "<p>Con todo lo anterior, podemos hacer el reconocimiento de cualquier digito que dibujes, ¿Estás list@?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a visualizar la imagen de un número que vas a crear en tu computador con la aplicación de paint, ésta imagen debe de tener un fondo negro y ser pintada en blanco, encontrarás un ejemplo en el repositorio\n",
    "image = plt.imread(____) # Coloca aquí la ruta de la imagen que hayas creado en formato jpg o png\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con esta libreria transformaremos la imagen creada a un formato de 28x28 pixeles\n",
    "from PIL import Image\n",
    "pil = Image.open(____)\n",
    "image_resize = pil.resize((28, 28))\n",
    "\n",
    "# Vamos transformar la nueva imagen en un array donde se almacenara la información de los pixeles\n",
    "pixels = np.asarray(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesitamos hacer algunas configuraciones a la imagen debido al formato de datos que esta alimentando al modelo y a la configuración de sklearn\n",
    "arr = pixels.transpose(2, 0, 1).reshape(-1, pixels.shape[1])[0:28]\n",
    "\n",
    "image_final = arr.ravel().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la predicción del modelo con el número que creaste, ¿Fue la clasificación correcta? :O\n",
    "print(\"El número es:\", ____)\n",
    "plt.imshow(arr, cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit and Underfit\n",
    "<p>¿Cual es mi numero ideal para elegir el parametro <i>k</i>? Vamos a calcular los valores de precisión para los conjuntos e entrenamiento y prueba para una rango de valores k. Al observar cómo difieren estos valores podremos observar cual es el mejor parametro sin caer en un <i>Overfit</i> o un <i>Underfit</i>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coniguración de arreglos iniciales\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop para diferentes valores de k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Clasificador k-NN para el parametro k\n",
    "    knn = ____\n",
    "\n",
    "    # Ajuste del clasificador al dataset de entrenamiento\n",
    "    ____\n",
    "    \n",
    "    # Calculo de precision sobre el dataset de entrenamiento\n",
    "    train_accuracy[i] = knn.score(____, ____)\n",
    "\n",
    "    # Calculo de precision sobre el dataset de prueba\n",
    "    test_accuracy[i] = ____(____, ____)\n",
    "\n",
    "# Grafico para encontrar un valor optimo de k\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.title('k-NN: by Number of Neighbors')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística\n",
    "<p>Haz la predicción de tu imagen, pero esta vez por medio de una Regresión Logística, ¿Cuál de los dos modelos te da mejores resultados?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
